{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "# Lab 2. PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "b4ab417c-ec86-49f4-d2f7-5dde74214a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.6.0+cpu'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "07646e3f-7785-4588-cff1-8584d707f9d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "642169d4-e993-414f-faae-e55f7361c925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def load_mnist(path, kind='train'):\n",
            "    import os\n",
            "    import gzip\n",
            "    import numpy as np\n",
            "\n",
            "    \"\"\"Load MNIST data from `path`\"\"\"\n",
            "    labels_path = os.path.join(path,\n",
            "                               '%s-labels-idx1-ubyte.gz'\n",
            "                               % kind)\n",
            "    images_path = os.path.join(path,\n",
            "                               '%s-images-idx3-ubyte.gz'\n",
            "                               % kind)\n",
            "\n",
            "    with gzip.open(labels_path, 'rb') as lbpath:\n",
            "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
            "                               offset=8)\n",
            "\n",
            "    with gzip.open(images_path, 'rb') as imgpath:\n",
            "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
            "                               offset=16).reshape(len(labels), 784)\n",
            "\n",
            "    return images, labels\n"
          ]
        }
      ],
      "source": [
        "#!cat data/utils/mnist_reader.py # linux / mac\n",
        "!type data\\utils\\mnist_reader.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "e22b73a7-8119-4f31-a21c-959cc7cd8269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['t10k-images-idx3-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'train-images-idx3-ubyte.gz',\n",
              " 'train-labels-idx1-ubyte.gz',\n",
              " 'unzipped']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "e5d0439e-4fa1-464f-b979-2bcc58146b65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "5432f7e8-73f3-45df-b599-8b8cecf9d9e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "c2754ce6-9cfd-4ad4-fcd0-d388b070bf19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "f5846705-56a4-42e1-b2c4-800103d06e23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# split data:\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X_train_full, y_train_full,\n",
        "        test_size = 0.5,\n",
        "        shuffle=True,\n",
        "        stratify = y_train_full,\n",
        "        random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r4gVzDXcR7u7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (30000, 784)\n",
            "X_valid shape: (30000, 784)\n",
            "y_train shape: (30000,)\n",
            "y_valid shape: (30000,)\n"
          ]
        }
      ],
      "source": [
        "# shape?\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "692b8a01-c969-4ef4-a07b-89d108274077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "b68234b3-9453-4b55-f531-c003f49b3e65"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "05e6546d-3801-4f65-fb98-ea20557c1634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "d759d04f-ca93-4a7b-f47d-70a417eb1540"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "caa1e39a-6f7a-4795-8e76-012ba4e91000"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['img_0.npy',\n",
              " 'img_1.npy',\n",
              " 'img_10.npy',\n",
              " 'img_100.npy',\n",
              " 'img_1000.npy',\n",
              " 'img_10000.npy',\n",
              " 'img_10001.npy',\n",
              " 'img_10002.npy',\n",
              " 'img_10003.npy',\n",
              " 'img_10004.npy']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST(Dataset):\n",
        "    def __init__(self, indices: NDArray[np.int32], labels: NDArray[np.int8]) -> None:\n",
        "        self.indices = indices\n",
        "        self.labels = labels\n",
        "        self.target_dir = 'data/data/fashion/unzipped'\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, int]:\n",
        "        index = self.indices[idx]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        image_path = os.path.join(self.target_dir, f'img_{index:d}.npy')\n",
        "        with open(image_path, 'rb') as f:\n",
        "            image_np = np.load(f)\n",
        "\n",
        "        image_np = image_np.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "        return image_np, label\n",
        "\n",
        "    @staticmethod\n",
        "    def create_split(fraction_train: float, fraction_validation: float, fraction_test: float,stratify: bool = True, shuffle: bool = True) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "\n",
        "        assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "        labels = np.load(os.path.join('data/data/fashion/unzipped', 'labels.npy')).astype(np.int8)\n",
        "        all_indices = np.arange(len(labels), dtype=np.int32)\n",
        "\n",
        "        # First split: train vs temp\n",
        "        train_indices, temp_indices, train_labels, temp_labels = train_test_split(\n",
        "            all_indices, labels,\n",
        "            test_size=(1 - fraction_train),\n",
        "            stratify=labels if stratify else None,\n",
        "            shuffle=shuffle,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Second split: validation vs test\n",
        "        valid_fraction = fraction_validation / (fraction_validation + fraction_test)\n",
        "\n",
        "        valid_indices, test_indices, valid_labels, test_labels = train_test_split(\n",
        "            temp_indices, temp_labels,\n",
        "            test_size=(1 - valid_fraction),\n",
        "            stratify=temp_labels if stratify else None,\n",
        "            shuffle=shuffle,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        data_train = FashionMNIST(train_indices, labels)\n",
        "        data_valid = FashionMNIST(valid_indices, labels)\n",
        "        data_test = FashionMNIST(test_indices, labels)\n",
        "\n",
        "        return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "6783da1f-b7c8-4f0b-faed-fc7b2cf4df5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "7155a52e-122b-4c8c-ed89-674a251e53d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "8e7848df-a758-4acd-88eb-73bb9151334b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "cd38ff45-61ec-40b1-c503-b40294f452f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "8f783847-a0b2-4331-d09f-bff8f096f741"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "ce9fadd4-012c-4627-b3cd-6ebf3299510b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0150,  0.0259,  0.0001,  ...,  0.0280, -0.0222, -0.0336],\n",
              "         [ 0.0184,  0.0008,  0.0186,  ...,  0.0202,  0.0338,  0.0231],\n",
              "         [ 0.0272,  0.0209, -0.0227,  ..., -0.0298,  0.0111,  0.0147],\n",
              "         ...,\n",
              "         [ 0.0122, -0.0132,  0.0071,  ..., -0.0097,  0.0208,  0.0313],\n",
              "         [ 0.0142, -0.0177,  0.0157,  ..., -0.0033, -0.0017,  0.0350],\n",
              "         [-0.0206, -0.0325, -0.0061,  ...,  0.0289, -0.0162, -0.0329]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-6.2197e-03,  8.4329e-03,  1.4285e-02,  7.7758e-03,  3.2077e-02,\n",
              "         -1.1143e-02,  2.3732e-02,  2.5440e-02,  2.9988e-02, -5.4131e-04,\n",
              "         -3.3531e-02, -6.4428e-03, -2.2352e-02, -1.7295e-02,  1.8381e-02,\n",
              "          3.5298e-02, -1.5658e-02, -2.0990e-02,  1.9210e-02, -2.7254e-02,\n",
              "         -2.8119e-02, -1.5501e-02, -2.1734e-02, -4.8323e-03, -9.4027e-04,\n",
              "         -2.7129e-03,  3.1970e-02,  3.0963e-02, -1.7986e-02,  1.8547e-02,\n",
              "         -2.0059e-02,  7.8501e-03,  2.2080e-02, -2.0393e-02, -3.1173e-02,\n",
              "         -1.8415e-02,  2.2347e-02, -8.3157e-03,  8.4095e-03,  3.4220e-02,\n",
              "          1.4312e-02,  2.2120e-02,  2.2631e-02,  7.4439e-03, -3.2083e-02,\n",
              "          1.2618e-02, -3.1471e-05, -3.4116e-02, -3.0420e-03,  1.5695e-03,\n",
              "         -1.1068e-02, -2.4738e-02, -1.5194e-02,  3.1140e-02, -8.1991e-03,\n",
              "         -2.9286e-02,  3.0755e-02,  1.7568e-02,  1.4312e-02,  3.9886e-03,\n",
              "         -1.8127e-02, -2.1370e-02,  2.9103e-03, -3.3667e-02,  2.8876e-02,\n",
              "         -2.2221e-02,  3.5267e-02,  1.7974e-02,  2.7719e-02, -2.2967e-02,\n",
              "         -4.4699e-03, -2.7638e-02, -3.6867e-03, -1.5029e-02,  1.3817e-02,\n",
              "         -1.1211e-02,  1.0901e-02,  1.9045e-02, -2.0223e-02, -3.5107e-02,\n",
              "          1.4860e-02, -3.1650e-02,  4.1886e-03,  2.5159e-04, -3.2050e-02,\n",
              "         -1.1186e-02,  7.9890e-03, -3.1299e-02, -2.7922e-02,  2.4934e-02,\n",
              "         -2.4845e-02,  3.2660e-02, -2.7603e-02,  1.8968e-03, -9.1318e-03,\n",
              "          2.5821e-02,  2.3289e-02, -2.8428e-02, -3.4902e-02, -1.3104e-02],\n",
              "        requires_grad=True)]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "cddc0c0f-a251-4b24-a385-f682a0a4eed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0150,  0.0259,  0.0001,  ...,  0.0280, -0.0222, -0.0336],\n",
              "          [ 0.0184,  0.0008,  0.0186,  ...,  0.0202,  0.0338,  0.0231],\n",
              "          [ 0.0272,  0.0209, -0.0227,  ..., -0.0298,  0.0111,  0.0147],\n",
              "          ...,\n",
              "          [ 0.0122, -0.0132,  0.0071,  ..., -0.0097,  0.0208,  0.0313],\n",
              "          [ 0.0142, -0.0177,  0.0157,  ..., -0.0033, -0.0017,  0.0350],\n",
              "          [-0.0206, -0.0325, -0.0061,  ...,  0.0289, -0.0162, -0.0329]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-6.2197e-03,  8.4329e-03,  1.4285e-02,  7.7758e-03,  3.2077e-02,\n",
              "          -1.1143e-02,  2.3732e-02,  2.5440e-02,  2.9988e-02, -5.4131e-04,\n",
              "          -3.3531e-02, -6.4428e-03, -2.2352e-02, -1.7295e-02,  1.8381e-02,\n",
              "           3.5298e-02, -1.5658e-02, -2.0990e-02,  1.9210e-02, -2.7254e-02,\n",
              "          -2.8119e-02, -1.5501e-02, -2.1734e-02, -4.8323e-03, -9.4027e-04,\n",
              "          -2.7129e-03,  3.1970e-02,  3.0963e-02, -1.7986e-02,  1.8547e-02,\n",
              "          -2.0059e-02,  7.8501e-03,  2.2080e-02, -2.0393e-02, -3.1173e-02,\n",
              "          -1.8415e-02,  2.2347e-02, -8.3157e-03,  8.4095e-03,  3.4220e-02,\n",
              "           1.4312e-02,  2.2120e-02,  2.2631e-02,  7.4439e-03, -3.2083e-02,\n",
              "           1.2618e-02, -3.1471e-05, -3.4116e-02, -3.0420e-03,  1.5695e-03,\n",
              "          -1.1068e-02, -2.4738e-02, -1.5194e-02,  3.1140e-02, -8.1991e-03,\n",
              "          -2.9286e-02,  3.0755e-02,  1.7568e-02,  1.4312e-02,  3.9886e-03,\n",
              "          -1.8127e-02, -2.1370e-02,  2.9103e-03, -3.3667e-02,  2.8876e-02,\n",
              "          -2.2221e-02,  3.5267e-02,  1.7974e-02,  2.7719e-02, -2.2967e-02,\n",
              "          -4.4699e-03, -2.7638e-02, -3.6867e-03, -1.5029e-02,  1.3817e-02,\n",
              "          -1.1211e-02,  1.0901e-02,  1.9045e-02, -2.0223e-02, -3.5107e-02,\n",
              "           1.4860e-02, -3.1650e-02,  4.1886e-03,  2.5159e-04, -3.2050e-02,\n",
              "          -1.1186e-02,  7.9890e-03, -3.1299e-02, -2.7922e-02,  2.4934e-02,\n",
              "          -2.4845e-02,  3.2660e-02, -2.7603e-02,  1.8968e-03, -9.1318e-03,\n",
              "           2.5821e-02,  2.3289e-02, -2.8428e-02, -3.4902e-02, -1.3104e-02],\n",
              "         requires_grad=True))]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "3e22976d-f24c-4a97-b81e-3c52cae159be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0150,  0.0259,  0.0001,  ...,  0.0280, -0.0222, -0.0336],\n",
              "        [ 0.0184,  0.0008,  0.0186,  ...,  0.0202,  0.0338,  0.0231],\n",
              "        [ 0.0272,  0.0209, -0.0227,  ..., -0.0298,  0.0111,  0.0147],\n",
              "        ...,\n",
              "        [ 0.0122, -0.0132,  0.0071,  ..., -0.0097,  0.0208,  0.0313],\n",
              "        [ 0.0142, -0.0177,  0.0157,  ..., -0.0033, -0.0017,  0.0350],\n",
              "        [-0.0206, -0.0325, -0.0061,  ...,  0.0289, -0.0162, -0.0329]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, dropout: float = 0.2) -> None:\n",
        "        super().__init__()\n",
        "        self.layer_input = nn.Linear(784, 300)\n",
        "        self.dropout_1 = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.hidden_1 = nn.Linear(300, 200)\n",
        "        self.dropout_2 = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.layer_output = nn.Linear(200, 10)  \n",
        "\n",
        "    def forward(self, x: pt.Tensor) -> pt.Tensor:\n",
        "        x = nn.functional.relu(self.layer_input(x))  \n",
        "        x = self.dropout_1(x)\n",
        "\n",
        "        x = nn.functional.relu(self.hidden_1(x))     \n",
        "        x = self.dropout_2(x)\n",
        "\n",
        "        x = self.layer_output(x)\n",
        "        return nn.functional.softmax(x, dim=-1)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=3, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer1',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "9d9b00c4-3688-430a-c018-9103e0ee85a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDh74y0i7fX",
        "outputId": "3540b42b-4dc9-4ec4-e0b2-2991c8681b63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.10588406, 0.08609498, 0.1143323 , 0.10949079, 0.09773725,\n",
              "        0.09056316, 0.09354023, 0.09385365, 0.10375261, 0.10475096],\n",
              "       [0.08283962, 0.0925359 , 0.12841073, 0.10872693, 0.10040214,\n",
              "        0.08835883, 0.10520107, 0.09139679, 0.07945882, 0.12266927],\n",
              "       [0.08844946, 0.08698359, 0.11342566, 0.12342601, 0.0894724 ,\n",
              "        0.08413946, 0.10419416, 0.09574035, 0.09681325, 0.11735573]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "y_proba = model(X_new) # this returns a probability?\n",
        "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8cAN3fi99y",
        "outputId": "f926d9e3-d1de-4e9b-c668-a5f69af07076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Pullover', 'Pullover', 'Dress'], dtype='<U11')"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "83b21833-f6f7-4424-ac0d-49c4334032c9"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (896x28 and 784x300)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[81], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m CustomNetwork()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# train model:\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# plot history:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m history[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_valid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[80], line 11\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, loader_train, loader_valid, epochs, lr)\u001b[0m\n\u001b[0;32m      8\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;66;03m# train for one epoch:\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m   loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;66;03m# evaluate on validation:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m   metrics \u001b[38;5;241m=\u001b[39m evaluate(model, loader_valid, loss_fn)\n",
            "Cell \u001b[1;32mIn[78], line 16\u001b[0m, in \u001b[0;36mepoch\u001b[1;34m(model, loader_train, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# create predictions:\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculate loss:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[42], line 13\u001b[0m, in \u001b[0;36mCustomNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: pt\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pt\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_1(x)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_1(x))     \n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (896x28 and 784x300)"
          ]
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "18d52ab3-0877-4be2-8958-1f8dd4c02219"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (896x28 and 784x300)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_test\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#evaluate on the test set\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[79], line 15\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, loader_valid, loss_fn)\u001b[0m\n\u001b[0;32m     12\u001b[0m labels\u001b[38;5;241m.\u001b[39mextend(y_batch\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# create predictions:\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m predictions\u001b[38;5;241m.\u001b[39mextend(y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculate loss:\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[42], line 13\u001b[0m, in \u001b[0;36mCustomNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: pt\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pt\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_1(x)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_1(x))     \n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (896x28 and 784x300)"
          ]
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pwOaMCDSTOpS"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "    # 1. set model to train:\n",
        "    model.train()\n",
        "    losses = None if loss_fn is None else []\n",
        "    with pt.enable_grad():\n",
        "        for X_batch, y_batch in loader_train:\n",
        "            # move tensors to correct device:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            # reset all gradients to zero:\n",
        "            optimizer.zero_grad()\n",
        "            # create predictions:\n",
        "            y_pred = model(X_batch)\n",
        "            # calculate loss:\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "            # backpropagate loss:\n",
        "            loss.backward()\n",
        "            # update weights:\n",
        "            optimizer.step()\n",
        "    return np.mean(losses)\n",
        "  \n",
        "  \n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "    # 1. set model to eval:\n",
        "    model.eval()\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    losses = None if loss_fn is None else []\n",
        "    for X_batch, y_batch in loader_valid:\n",
        "        # move tensors to correct device:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        labels.extend(y_batch.cpu().detach().numpy())\n",
        "        # create predictions:\n",
        "        y_pred = model(X_batch)\n",
        "        predictions.extend(y_pred.cpu().detach().numpy())\n",
        "        # calculate loss:\n",
        "        if loss_fn is not None:\n",
        "            losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "    # calculate f1 score:\n",
        "    f1 = f1_score(\n",
        "        y_batch.cpu().detach().numpy(),\n",
        "        y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "        average='macro'\n",
        "    )\n",
        "    if loss_fn is None: return {'f1':f1}\n",
        "    else: return {'loss':np.mean(losses), 'f1':f1}\n",
        "\n",
        "\n",
        "def fit(model, loader_train: DataLoader, loader_valid: DataLoader, epochs: int, lr: float, patience: int = 5):\n",
        "    optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = pt.optim.lr_scheduler.LinearLR(optimizer=optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)\n",
        "    loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "    history = []\n",
        "    best_loss = float('inf')\n",
        "    best_params = None\n",
        "    counter = 0\n",
        "\n",
        "    for i in range(epochs):\n",
        "        loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "        history.append({\n",
        "            'loss_train': loss_train,\n",
        "            'loss_valid': metrics['loss'],\n",
        "            'f1_valid': metrics['f1']\n",
        "        })\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if metrics['loss'] < best_loss:\n",
        "            best_loss = metrics['loss']\n",
        "            best_params = model.state_dict()\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "\n",
        "        if counter >= patience:\n",
        "            break\n",
        "\n",
        "    if best_params is not None:\n",
        "        model.load_state_dict(best_params)\n",
        "\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_df.attrs['early_stopping_triggered'] = counter >= patience\n",
        "    return history_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "dd43ea93-c413-4390-f3cc-a53d2aa2076d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexXOBTKUZH_",
        "outputId": "6cb76ada-270e-46ec-a15f-a3fc0f7a5c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuVaeSJZgW0",
        "outputId": "e6e1e1d6-0055-4ec0-a53c-2ab7d04af24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -O filename.ext 'https://www.google.com/url?q=https%3A%2F%2Fnextilearn.dsv.su.se%2Fmod%2Fresource%2Fview.php%3Fid%3D25386'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpmUlavla3Py",
        "outputId": "a039de5d-514b-4452-baf0-efcfa18b4759"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['data',\n",
              " 'Lab2_final.ipynb',\n",
              " 'model.pt',\n",
              " 'model_state_dict.pkl',\n",
              " 'submission.csv',\n",
              " 'task5']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.1 download https://www.google.com/url?q=https%3A%2F%2Fnextilearn.dsv.su.se%2Fmod%2Fresource%2Fview.php%3Fid%3D25386 \n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Create Data Pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "NQ_Rj925R7vY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' scaler = StandardScaler()\\nsc_train = scaler.fit_transform(data_train)\\nsc_test = scaler.transform(data_test) '"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2.1 load training data:\n",
        "data_train = pd.read_csv('task5/data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('task5/labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 load test data (no labels):\n",
        "data_test = pd.read_csv('task5/data_test.csv', index_col=0)\n",
        "\n",
        "\"\"\" scaler = StandardScaler()\n",
        "sc_train = scaler.fit_transform(data_train)\n",
        "sc_test = scaler.transform(data_test) \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(8,24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6,1)\n",
        ")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "_dqM_Yzyb1ho"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import tqdm\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_train = labels_train[\"MedHouseVal\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train,X_test, y_train, y_test = train_test_split(data_train,labels_train,\n",
        "                                                   train_size=0.7,shuffle = True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train,dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "\n",
        "#training parameters\n",
        "n_epochs = 100\n",
        "batch_size = 32\n",
        "batch_start = torch.arange(0,len(X_train),batch_size)\n",
        "\n",
        "#save the best model\n",
        "best_mse = np.inf\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "#training loop\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", minterval = 0, disable=True)as bar:\n",
        "        bar.set_description(f\"Eposh - {epoch}\")\n",
        "\n",
        "        for start in bar:\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred,y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    \n",
        "    #evaluate accuracy at the end of the epoch\n",
        "    model.eval()\n",
        "    y_pred=model(X_test)\n",
        "    mse =loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_test_scaled = scaler.transform(data_test)\n",
        "#convert to pytorch tensor\n",
        "X_new_tensor = torch.tensor(data_test_scaled, dtype=torch.float32)\n",
        "#make the predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediciton = model(X_new_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "predictions",
                  "rawType": "float32",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "556fe527-51f0-4b73-b740-f2d9aa62742a",
              "rows": [
                [
                  "0",
                  "2.1645923"
                ],
                [
                  "1",
                  "3.5089626"
                ],
                [
                  "2",
                  "3.4923918"
                ],
                [
                  "3",
                  "0.9891959"
                ],
                [
                  "4",
                  "2.6654592"
                ],
                [
                  "5",
                  "4.549978"
                ],
                [
                  "6",
                  "2.7236755"
                ],
                [
                  "7",
                  "1.9263353"
                ],
                [
                  "8",
                  "2.7123358"
                ],
                [
                  "9",
                  "2.0710726"
                ],
                [
                  "10",
                  "1.2634841"
                ],
                [
                  "11",
                  "2.1836753"
                ],
                [
                  "12",
                  "1.4551592"
                ],
                [
                  "13",
                  "1.4114988"
                ],
                [
                  "14",
                  "2.1604269"
                ],
                [
                  "15",
                  "3.3947551"
                ],
                [
                  "16",
                  "1.6759129"
                ],
                [
                  "17",
                  "3.6357186"
                ],
                [
                  "18",
                  "1.9061615"
                ],
                [
                  "19",
                  "4.2719116"
                ],
                [
                  "20",
                  "1.3005548"
                ],
                [
                  "21",
                  "1.4115717"
                ],
                [
                  "22",
                  "2.0549572"
                ],
                [
                  "23",
                  "2.7275722"
                ],
                [
                  "24",
                  "1.8013084"
                ],
                [
                  "25",
                  "1.29389"
                ],
                [
                  "26",
                  "2.2422433"
                ],
                [
                  "27",
                  "1.1796818"
                ],
                [
                  "28",
                  "1.634588"
                ],
                [
                  "29",
                  "1.6667328"
                ],
                [
                  "30",
                  "1.4480398"
                ],
                [
                  "31",
                  "1.2012565"
                ],
                [
                  "32",
                  "2.8532612"
                ],
                [
                  "33",
                  "2.7940266"
                ],
                [
                  "34",
                  "1.4411359"
                ],
                [
                  "35",
                  "0.5284973"
                ],
                [
                  "36",
                  "2.1706474"
                ],
                [
                  "37",
                  "1.1500211"
                ],
                [
                  "38",
                  "0.8669289"
                ],
                [
                  "39",
                  "1.5842395"
                ],
                [
                  "40",
                  "1.6034946"
                ],
                [
                  "41",
                  "1.5805662"
                ],
                [
                  "42",
                  "2.2831745"
                ],
                [
                  "43",
                  "3.5805712"
                ],
                [
                  "44",
                  "2.1885774"
                ],
                [
                  "45",
                  "2.4233887"
                ],
                [
                  "46",
                  "1.8388016"
                ],
                [
                  "47",
                  "1.8612568"
                ],
                [
                  "48",
                  "2.861162"
                ],
                [
                  "49",
                  "2.065353"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 4128
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.164592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.508963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.492392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.989196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.665459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4123</th>\n",
              "      <td>3.025965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4124</th>\n",
              "      <td>4.515234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4125</th>\n",
              "      <td>0.799043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4126</th>\n",
              "      <td>3.325064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4127</th>\n",
              "      <td>3.394372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4128 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      predictions\n",
              "0        2.164592\n",
              "1        3.508963\n",
              "2        3.492392\n",
              "3        0.989196\n",
              "4        2.665459\n",
              "...           ...\n",
              "4123     3.025965\n",
              "4124     4.515234\n",
              "4125     0.799043\n",
              "4126     3.325064\n",
              "4127     3.394372\n",
              "\n",
              "[4128 rows x 1 columns]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = pd.DataFrame(prediciton.detach().cpu().numpy(), columns=['predictions'])\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "V_gqdJvucm2l"
      },
      "outputs": [],
      "source": [
        "predictions.to_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
